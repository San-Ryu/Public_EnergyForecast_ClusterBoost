{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Hist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - CODE : KIER M02 - Clustering\n",
    " - DESC  \n",
    "    &ensp; : 최적의 Cluster를 선정하기 위한 정량적 비교  \n",
    "    &emsp; 1) Inertia 기반의 Elbow-Method  \n",
    "    &emsp; 2) 군집화 계수 비교 : Silhouette / CHI / Dunn Index  \n",
    "\n",
    "  - DATE  \n",
    "    &ensp; 2024-02-01 Created  \n",
    "    &ensp; 2024-04-03 코드 개선  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; 1) KIER M02 초기부분 공통코드화  \n",
    "    &ensp; 2024-04-04 Updated  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; 1) 기능 구현 완료 및 논문 작성    \n",
    "    &ensp; 2024-07-23 Updated  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; 1) Dunn Index 부분 추가    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-01. Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-01-01. Init_Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region Basic_Import\n",
    "## Basic\n",
    "import os, sys, warnings\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.path.dirname(os.path.abspath('./__file__'))\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('./__file__'))))\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "pd.options.display.float_format = '{:.10f}'.format\n",
    "\n",
    "import math, random\n",
    "\n",
    "## Datetime\n",
    "import time, datetime as dt\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "## glob\n",
    "import glob, requests, json\n",
    "from glob import glob\n",
    "\n",
    "## 시각화\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "# %matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "## Split, 정규화\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# K-Means 알고리즘\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "# Clustering 알고리즘의 성능 평가 측도\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score, silhouette_score, rand_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "## For Web\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlencode, unquote, quote_plus\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "#endregion Basic_Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import_DL\n",
    "str_tar = \"tf\"\n",
    "## For Torch\n",
    "if str_tar == \"torch\":\n",
    "    import torch, torch.nn as nn\n",
    "    from torch.nn.utils import weight_norm\n",
    "    print(\"Torch Imported\")\n",
    "## For TF\n",
    "elif str_tar == \"tf\":\n",
    "    import tensorflow as tf, tensorflow_addons as tfa\n",
    "    from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "    from keras.models import Sequential, load_model\n",
    "    from keras_flops import get_flops\n",
    "    print(\"Tensorflow Imported\")\n",
    "else:\n",
    "    print(\"Error : Cannot be used except for Keywords\")\n",
    "    print(\" : torch / tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import_Local\n",
    "from Src_Dev_Common import Data_Datetime as com_date, KMA_Weather as com_KMA, KECO_AirKor as com_KECO, KASI_Holiday as com_Holi, KIER_Usage_M02 as com_KIER_M02, Data_Clustering as com_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-01-02. Config (Directory, Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Init_config\n",
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"], os.environ['TF_DETERMINISTIC_OPS'] = str(SEED), \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Todate str\n",
    "str_now_ymd = pd.datetime.now().date()\n",
    "str_now_y, str_now_m, str_now_d = pd.datetime.now().year, pd.datetime.now().month, pd.datetime.now().day\n",
    "str_now_hr, str_now_min = pd.datetime.now().hour, pd.datetime.now().minute\n",
    "\n",
    "print(pd.datetime.now())\n",
    "print(str(str_now_y) + \" / \" + str(str_now_m)  + \" / \" + str(str_now_d))\n",
    "print(str(str_now_hr) + \" : \" + str(str_now_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dict_Domain\n",
    "## {0:\"ELEC\", 1:\"HEAT\", 2:\"WATER\", 3:\"HOT_HEAT\", 4:\"HOT_FLOW\", 99:\"GAS\"}\n",
    "## {0 : '10MIN', 1 : '30MIN', 2 : '1H', 3 : '12H', 4 : '1D', 5 : '1W', 6 : '2W', 7 : '1M'}\n",
    "int_domain, int_interval = 0, 4\n",
    "\n",
    "## Domain, ACCU/INST Column\n",
    "str_domain, str_col_accu, str_col_inst = com_KIER_M02.create_domain_str(int_domain)\n",
    "## Directory Root\n",
    "str_dirData, str_dir_raw, str_dir_cleansed, str_dirName_bld, str_dirName_h = com_KIER_M02.create_dir_str(str_domain)\n",
    "## Interval, Target File\n",
    "str_interval, str_fileRaw, str_fileRaw_hList, str_file = com_KIER_M02.create_file_str(str_domain, int_interval)\n",
    "\n",
    "print(str(os.listdir(str_dirData)) + \"\\n\")\n",
    "print(os.listdir(str_dirName_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-02. Data Load (df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-02-01. KIER (Energy Usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kier_raw = pd.read_csv(str_dirName_h + str_file, index_col = 0)\n",
    "\n",
    "try : df_kier_raw['METER_DATE'] = pd.to_datetime(df_kier_raw['METER_DATE'])\n",
    "except KeyError : df_kier_raw = com_date.create_col_datetime(df_kier_raw, 'METER_DATE', 'YEAR', 'MONTH', 'DAY', 'HOUR', 'MINUTE').drop(labels = ['None'], axis = 1)\n",
    "\n",
    "print(df_kier_raw.isna().sum().sum())\n",
    "df_kier_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 호실별 순시 사용량 컬럼만 가져오기\n",
    "# list_col_tar = list(df_kier_raw.columns[6:-2]) ## 10MIN\n",
    "list_col_tar = list(df_kier_raw.columns[1:]) ## 1H / 1D\n",
    "df_kier_h = df_kier_raw.set_index('METER_DATE')\n",
    "df_kier_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list_col_tar))\n",
    "list_col_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Error Log : \"[5:-2]\" 부분을 추가하여 연월일시 및 평균합계 부분을 제거해주지 않으면, 군집화 계수가 제대로 도출되지 못함.\n",
    "# df_kier_summary_total = df_kier_h.transpose().reset_index()[5:-2]\n",
    "# ## 또는, 가장 깔끔하게 이렇게 처리해도 좋다\n",
    "df_kier_summary_total = df_kier_h[list_col_tar].transpose().reset_index()\n",
    "\n",
    "## 세대 번호의 컬럼명이 'index'로 지정되어 오류 발생\n",
    "df_kier_summary_total['h_index'] = df_kier_summary_total['index']\n",
    "df_kier_summary_total = df_kier_summary_total.drop(columns = ['index'])\n",
    "df_kier_summary_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_kier_summary_total.drop(columns = 'h_index')\n",
    "y = df_kier_summary_total['h_index']\n",
    "X.isna().sum()\n",
    "# y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://bigdata.dongguk.ac.kr/lectures/datascience/_book/%EA%B5%B0%EC%A7%91%EB%B6%84%EC%84%9D.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 표준화\n",
    "scaler = StandardScaler() # 변수 표준화 클래스\n",
    "scaler.fit(X)  # 표준화를 위해 변수별 파라미터(평균, 표준편차) 계산\n",
    "# scaler.mean_, scaler.scale_\n",
    "X_std = scaler.transform(X)  # 훈련자료 표준화 변환\n",
    "# X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering (군집화) : K - Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "군집의 수 결정 방법  \n",
    "1) elbow method - 군집의 개수와 군집내 변동의 합을 그래프로 나타내고, 변동량의 변화가 작아지는 지점의 군집의 수를 적정 군집의 수로 결정함  \n",
    "2) 군집화시 계수 비교 : Silhouette / CHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 군집시 군집의 수 판단을 위한 Data 수집, 이를 바탕으로 인사이트 도출\n",
    "int_cluster_min, int_cluster_max = 2, 10 ## 최소 / 최대 군집 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_intertia, list_intertia_deriv = com_clustering.clustering_elbow_method(str_interval, int_cluster_min, int_cluster_max, X_std, opt_X = 3)\n",
    "print(list_intertia)\n",
    "print(list_intertia_deriv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_CHI = com_clustering.clustering_CHI_method(str_interval, int_cluster_min, int_cluster_max, X_std, 2)\n",
    "print(list_CHI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_Silhouette, list_cnt_clusters_by_K = com_clustering.clustering_Silhouette_method(str_interval, int_cluster_min, int_cluster_max, X_std, 2)\n",
    "print(list_Silhouette)\n",
    "print(list_cnt_clusters_by_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Src_Dev_Common.cluster_eval import get_Dunn_index\n",
    "\n",
    "opt_X = 2\n",
    "\n",
    "## 예외처리01\n",
    "## Min이 Max보다 크면 그냥 바꿔줌 + Int가 아니면 Int로 바꿔줌\n",
    "if int_cluster_min > int_cluster_max : int_clusters_min, int_clusters_max = int(int_cluster_max), int(int_cluster_min) + 1\n",
    "else : int_clusters_min, int_clusters_max = int(int_cluster_min), int(int_cluster_max) + 1\n",
    "\n",
    "## 초기 변수  생성\n",
    "list_Dunn = []\n",
    "K = range(int_clusters_min, int_clusters_max)\n",
    "\n",
    "for n_cluster in K:\n",
    "    km_dunn = KMeans(n_clusters = n_cluster, init=\"k-means++\", max_iter=300, n_init=1).fit(X_std) \n",
    "    cluster = km_dunn.predict(X_std)\n",
    "    list_Dunn.append(get_Dunn_index(X_std, cluster))\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "fig.set_facecolor('white')\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(K, list_Dunn, marker='.', markersize = 5, zorder = 2)\n",
    "if opt_X != None : plt.scatter(opt_X, list_Dunn[opt_X - 2], color = 'red', marker = '^', label = 'Point', zorder = 9999)\n",
    "ax.set_xticks(K)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Dunn Index')\n",
    "plt.title('Dunn Index by number of clusters (Interval : ' + str_interval + ')')\n",
    "plt.show()\n",
    "\n",
    "print(list_Dunn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선정된 군집의 수에 따라 군집화 시뮬레이션 시행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 위에서 결정된 군집의 수에 따라 군집화 결과 도출\n",
    "## 초기 변수 생성\n",
    "K, cnt_loop = 3, 10 ## K : 결정된/평가할 군집의 수, cnt_loop : 평가를 위한 군집화 시도 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, 10): ## 1W / 1M 이외\n",
    "km = KMeans(n_clusters = K, init=\"k-means++\", max_iter=300, n_init=1).fit(X_std)\n",
    "cluster = km.predict(X_std)\n",
    "\n",
    "list_log_clusters = com_clustering.clustering_get_cnt_by_loop(K, cnt_loop, X_std)\n",
    "print(\"총 \" + str(cnt_loop) + \"회에 걸친 군집화 시뮬레이션\")\n",
    "print(list_log_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 최종 군집에 대한 군집화 평가 및 Labeled Data 저장\n",
    "print(com_clustering.get_cluster_sizes(km, X_std)) ## 최종 군집화에 대한 군집 크기 출력\n",
    "\n",
    "com_clustering.clustering_visualization(str_interval, km, X_std)\n",
    "list_scores = com_clustering.get_clustring_score(km, X_std, y)\n",
    "\n",
    "# df_kier_summary_total['target'] = np.transpose(np.where(km.labels_ == i)[0])\n",
    "df_kier_summary_total['target_'+str_domain] = 0\n",
    "for i in range(0, len(df_kier_summary_total)) : df_kier_summary_total['target_'+str_domain].iloc[i] = km.labels_[i]\n",
    "# df_kier_summary_total[['h_index', 'target_' + str_domain]]\n",
    "\n",
    "str_file_labeled = str_dirName_h + 'KIER_' + str(str_domain) + '_Labeled_' + str_interval + '_K' + str(K) + '.csv'\n",
    "df_kier_summary_total = df_kier_summary_total[['h_index', 'target_'+str_domain]]\n",
    "df_kier_summary_total.to_csv(str_file_labeled)\n",
    "print(str_file_labeled)\n",
    "df_kier_summary_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "dev-ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
