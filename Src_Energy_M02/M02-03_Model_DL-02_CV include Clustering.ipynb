{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Hist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - CODE : Model - KIER Method 02(Clustering)  \n",
    " - DESC : 각 군집별 Model Analysis 및 Evaluation  \n",
    " - DATE  \n",
    "   &ensp; 2024-08-20 Created : \"M02-03_Model_ML-01_Single.ipynb\"에 Clustering 및 각 군집화 Case별 Cross Validation 적용  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-01. Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-01-01. Init_Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region Basic_Import\n",
    "## Basic\n",
    "import os, sys, warnings\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.path.dirname(os.path.abspath('./__file__'))\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('./__file__'))))\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "pd.options.display.float_format = '{:.10f}'.format\n",
    "\n",
    "import math, random\n",
    "\n",
    "## Datetime\n",
    "import time, datetime as dt\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "## glob\n",
    "import glob, requests, json\n",
    "from glob import glob\n",
    "\n",
    "## 시각화\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "# %matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "## Split, 정규화\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# K-Means 알고리즘\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "# Clustering 알고리즘의 성능 평가 측도\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score, silhouette_score, rand_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "## Modeling, Model Training\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "\n",
    "## Grid Search\n",
    "# kfold = KFold(n_splits = 5, shuffle = False, random_state = None)\n",
    "\n",
    "## For Web\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlencode, unquote, quote_plus\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "#endregion Basic_Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Imported\n"
     ]
    }
   ],
   "source": [
    "## Import_DL\n",
    "str_tar = \"tf\"\n",
    "## For Torch\n",
    "if str_tar == \"torch\":\n",
    "    import torch, torch.nn as nn\n",
    "    from torch.nn.utils import weight_norm\n",
    "    print(\"Torch Imported\")\n",
    "## For TF\n",
    "elif str_tar == \"tf\":\n",
    "    import tensorflow as tf, tensorflow_addons as tfa\n",
    "    from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "    from keras.models import Sequential, load_model\n",
    "    from keras_flops import get_flops\n",
    "    print(\"Tensorflow Imported\")\n",
    "else:\n",
    "    print(\"Error : Cannot be used except for Keywords\")\n",
    "    print(\" : torch / tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import_Local\n",
    "from Src_Dev_Common import Common_Model_DL as com_DL, Data_Datetime as com_date, KMA_Weather as com_KMA, KECO_AirKor as com_KECO, KASI_Holiday as com_Holi, KIER_Usage_M02 as com_KIER_M02, Data_Analysis as com_Analysis, Data_Clustering as com_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-01-02. Config (Directory, Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Init_config\n",
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"], os.environ['TF_DETERMINISTIC_OPS'] = str(SEED), \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-25 13:38:15.297243\n",
      "2024 / 9 / 25\n",
      "13 : 38\n"
     ]
    }
   ],
   "source": [
    "## Define Todate str\n",
    "str_now_ymd = pd.datetime.now().date()\n",
    "str_now_y, str_now_m, str_now_d = pd.datetime.now().year, pd.datetime.now().month, pd.datetime.now().day\n",
    "str_now_hr, str_now_min = pd.datetime.now().hour, pd.datetime.now().minute\n",
    "\n",
    "print(pd.datetime.now())\n",
    "print(str(str_now_y) + \" / \" + str(str_now_m)  + \" / \" + str(str_now_d))\n",
    "print(str(str_now_hr) + \" : \" + str(str_now_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-01. 군집화 부분 함수화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-01-01. KIER (Energy Usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_label():\n",
    "    df_kier_raw = pd.read_csv(str_dirName_h + str_file, index_col = 0)\n",
    "    df_kier_raw['METER_DATE'] = pd.to_datetime(df_kier_raw['METER_DATE'])\n",
    "\n",
    "    ## 호실별 순시 사용량 컬럼만 가져오기\n",
    "    list_col_tar = list(df_kier_raw.columns[1:])\n",
    "    df_kier_h = df_kier_raw.set_index('METER_DATE')\n",
    "\n",
    "    # ## Error Log : \"[5:-2]\" 부분을 추가하여 연월일시 및 평균합계 부분을 제거해주지 않으면, 군집화 계수가 제대로 도출되지 못함.\n",
    "    # df_kier_summary_total = df_kier_h.transpose().reset_index()[5:-2]\n",
    "    # ## 또는, 가장 깔끔하게 이렇게 처리해도 좋다\n",
    "    df_kier_summary_total = df_kier_h[list_col_tar].transpose().reset_index()\n",
    "\n",
    "    ## 세대 번호의 컬럼명이 'index'로 지정되어 오류 발생\n",
    "    df_kier_summary_total['h_index'] = df_kier_summary_total['index']\n",
    "    df_kier_summary_total = df_kier_summary_total.drop(columns = ['index'])\n",
    "\n",
    "    X = df_kier_summary_total.drop(columns = 'h_index')\n",
    "    y = df_kier_summary_total['h_index']\n",
    "\n",
    "    # 변수 표준화\n",
    "    scaler = StandardScaler() # 변수 표준화 클래스\n",
    "    scaler.fit(X)  # 표준화를 위해 변수별 파라미터(평균, 표준편차) 계산\n",
    "    X_std = scaler.transform(X)  # 훈련자료 표준화 변환\n",
    "\n",
    "    ## 최종 군집에 대한 Labeled Data 저장\n",
    "    km = KMeans(n_clusters = K, init=\"k-means++\", max_iter=300, n_init=1).fit(X_std)\n",
    "    list_size_cluster = com_clustering.get_cluster_sizes(km, X_std) ## 최종 군집화에 대한 군집 크기\n",
    "    df_kier_summary_total['target_'+str_domain] = 0\n",
    "    for i in range(0, len(df_kier_summary_total)) : df_kier_summary_total['target_'+str_domain].iloc[i] = km.labels_[i]\n",
    "\n",
    "    str_file_labeled = str_dirName_h + 'KIER_' + str(str_domain) + '_Labeled_' + str_interval + '_K' + str(K) + '.csv'\n",
    "    df_kier_summary_total = df_kier_summary_total[['h_index', 'target_'+str_domain]]\n",
    "    df_kier_summary_total.to_csv(str_file_labeled)\n",
    "\n",
    "    return df_kier_summary_total, list_size_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-02. Data Load 및 준비 부분 함수화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-02-01. KMA ASOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_Not_cluster():\n",
    "    ## ▶ Dataset 불러오기\n",
    "    ## 1. Interpolate / Filled ASOS Data\n",
    "    str_file = '../data_Energy_KIER/KMA_ASOS_119_2010_2023_1st_to CSV.csv'\n",
    "    df_ASOS = pd.read_csv(str_file, index_col = 0).reset_index()\n",
    "\n",
    "    try : df_ASOS['METER_DATE'] = pd.to_datetime(df_ASOS['METER_DATE'])\n",
    "    except KeyError : df_kier_raw = com_date.create_col_datetime(df_ASOS, 'METER_DATE', 'YEAR', 'MONTH', 'DAY', 'HOUR', 'MINUTE').drop(labels = ['None'], axis = 1)\n",
    "\n",
    "    ## 3. 1시간 단위 사용량 Data Load\n",
    "    str_file = 'KIER_' + str_domain + '_INST_1H_Resampled.csv'\n",
    "    df_raw = pd.read_csv(str_dirName_h + str_file, index_col = 0)\n",
    "\n",
    "    ## ▶ h_index에 따라 Dataset 분리\n",
    "    ## 1. 각 index별 house 목록 생성\n",
    "    list_kier_h_all = df_kier_h_cluster['h_index']\n",
    "\n",
    "    ## 2. 전체 사용량 합계 구하기\n",
    "    df_kier_h_all = df_raw.copy()\n",
    "    df_kier_h_all['METER_DATE'] = pd.to_datetime(df_kier_h_all['METER_DATE'])\n",
    "    df_kier_h_tmp = df_raw[list_kier_h_all]\n",
    "    df_kier_h_all[str_domain + '_INST_SUM_ALL'] = df_kier_h_tmp.sum(axis = 1)\n",
    "    ## 시점을 밀어서, 세대별 사용량을 과거 사용량으로 사용\n",
    "    df_kier_h_all[str_domain + '_INST_SUM_ALL'] = df_kier_h_all[str_domain + '_INST_SUM_ALL'].shift(1)\n",
    "    df_kier_h_all.dropna()\n",
    "\n",
    "    ## 4. 날씨 데이터 추가\n",
    "    df_kier_h_all = pd.merge(df_kier_h_all, df_ASOS, how = 'left', on = ['METER_DATE'])\n",
    "    df_kier_h_all = com_KMA.Interpolate_KMA_ASOS(df_kier_h_all)\n",
    "    df_kier_h_all = com_date.create_col_ymdhm(df_kier_h_all, 'METER_DATE')\n",
    "\n",
    "    # str_col_tar = str_domain + '_INST_SUM_' + dict_grp[int_grp]\n",
    "    str_col_tar = str_domain + '_INST_SUM_ALL'\n",
    "    df_tar_res = df_kier_h_all.drop(columns = ['METER_DATE', 'DAY']).dropna()\n",
    "\n",
    "    return df_tar_res, str_col_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_cluster(int_grp):\n",
    "    ## ▶ Dataset 불러오기\n",
    "    ## 1. Interpolate / Filled ASOS Data\n",
    "    str_file = '../data_Energy_KIER/KMA_ASOS_119_2010_2023_1st_to CSV.csv'\n",
    "    df_ASOS = pd.read_csv(str_file, index_col = 0).reset_index()\n",
    "\n",
    "    try : df_ASOS['METER_DATE'] = pd.to_datetime(df_ASOS['METER_DATE'])\n",
    "    except KeyError : df_kier_raw = com_date.create_col_datetime(df_ASOS, 'METER_DATE', 'YEAR', 'MONTH', 'DAY', 'HOUR', 'MINUTE').drop(labels = ['None'], axis = 1)\n",
    "\n",
    "    ## 2. Labeled Data Load\n",
    "    ## Cluster 기준 Interval\n",
    "    str_file_clustering = 'KIER_' + str(str_domain) + '_Labeled_' + str_interval + '_K' + str(K) + '.csv'\n",
    "    df_kier_h_cluster = pd.read_csv(str_dirName_h + str_file_clustering\n",
    "                                    , index_col = 0).rename(columns = {'index' : 'h_index'})[['h_index', 'target_' + str_domain]]\n",
    "    # print(str_interval)\n",
    "    # print(df_kier_h_cluster['target_' + str_domain].drop_duplicates())\n",
    "    # df_kier_h_cluster\n",
    "\n",
    "    ## 3. 1시간 단위 사용량 Data Load\n",
    "    str_file = 'KIER_' + str_domain + '_INST_1H_Resampled.csv'\n",
    "    df_raw = pd.read_csv(str_dirName_h + str_file, index_col = 0)\n",
    "\n",
    "\n",
    "\n",
    "    ## ▶ h_index에 따라 Dataset 분리\n",
    "    ## 1. 각 index별 house 목록 생성\n",
    "    list_kier_h_all = df_kier_h_cluster['h_index']\n",
    "    # print(len(list_kier_h_all))\n",
    "    list_kier_h_c0 = df_kier_h_cluster[df_kier_h_cluster['target_' + str_domain] == 0]['h_index']\n",
    "    # print(len(list_kier_h_c0))\n",
    "    list_kier_h_c1 = df_kier_h_cluster[df_kier_h_cluster['target_' + str_domain] == 1]['h_index']\n",
    "    # print(len(list_kier_h_c1))\n",
    "\n",
    "    if K == 3 : list_kier_h_c2 = df_kier_h_cluster[df_kier_h_cluster['target_' + str_domain] == 2]['h_index']\n",
    "    # print(len(list_kier_h_c2))\n",
    "\n",
    "    ## 2. 전체 사용량 합계 구하기\n",
    "    df_kier_h_all = df_raw.copy()\n",
    "    df_kier_h_all['METER_DATE'] = pd.to_datetime(df_kier_h_all['METER_DATE'])\n",
    "    df_kier_h_tmp = df_raw[list_kier_h_all]\n",
    "    df_kier_h_all[str_domain + '_INST_SUM_ALL'] = df_kier_h_tmp.sum(axis = 1)\n",
    "    ## 시점을 밀어서, 세대별 사용량을 과거 사용량으로 사용\n",
    "    df_kier_h_all[str_domain + '_INST_SUM_ALL'] = df_kier_h_all[str_domain + '_INST_SUM_ALL'].shift(1)\n",
    "    df_kier_h_all.dropna()\n",
    "\n",
    "    ## 3. Cluster별 사용량 합계 산출\n",
    "    ## ■ C00\n",
    "    df_kier_h_c0 = df_raw.copy()[list_kier_h_c0]\n",
    "    df_kier_h_c0['METER_DATE'] = pd.to_datetime(df_kier_h_all['METER_DATE'])\n",
    "    df_kier_h_tmp = df_raw[list_kier_h_c0]\n",
    "    df_kier_h_c0[str_domain + '_INST_SUM_C0'] = df_kier_h_tmp.sum(axis = 1)\n",
    "    ## 시점을 밀어서, 세대별 사용량을 과거 사용량으로 사용\n",
    "    df_kier_h_c0[str_domain + '_INST_SUM_C0'] = df_kier_h_c0[str_domain + '_INST_SUM_C0'].shift(1)\n",
    "    df_kier_h_c0.dropna()\n",
    "\n",
    "    ## ■ C01\n",
    "    df_kier_h_c1 = df_raw.copy()[list_kier_h_c1]\n",
    "    df_kier_h_c1['METER_DATE'] = pd.to_datetime(df_kier_h_all['METER_DATE'])\n",
    "    df_kier_h_tmp = df_raw[list_kier_h_c1]\n",
    "    df_kier_h_c1[str_domain + '_INST_SUM_C1'] = df_kier_h_tmp.sum(axis = 1)\n",
    "    ## 시점을 밀어서, 세대별 사용량을 과거 사용량으로 사용\n",
    "    df_kier_h_c1[str_domain + '_INST_SUM_C1'] = df_kier_h_c1[str_domain + '_INST_SUM_C1'].shift(1)\n",
    "    df_kier_h_c1.dropna()\n",
    "\n",
    "    if K == 3:\n",
    "        ## ■ C02\n",
    "        df_kier_h_c2 = df_raw.copy()[list_kier_h_c2]\n",
    "        df_kier_h_c2['METER_DATE'] = pd.to_datetime(df_kier_h_all['METER_DATE'])\n",
    "        df_kier_h_tmp = df_raw[list_kier_h_c2]\n",
    "        df_kier_h_c2[str_domain + '_INST_SUM_C2'] = df_kier_h_tmp.sum(axis = 1)\n",
    "        ## 시점을 밀어서, 세대별 사용량을 과거 사용량으로 사용\n",
    "        df_kier_h_c2[str_domain + '_INST_SUM_C2'] = df_kier_h_c2[str_domain + '_INST_SUM_C2'].shift(1)\n",
    "        df_kier_h_c2.dropna()\n",
    "\n",
    "    ## 4. 날씨 데이터 추가\n",
    "    df_kier_h_all = pd.merge(df_kier_h_all, df_ASOS, how = 'left', on = ['METER_DATE'])\n",
    "    df_kier_h_all = com_KMA.Interpolate_KMA_ASOS(df_kier_h_all)\n",
    "    df_kier_h_all = com_date.create_col_ymdhm(df_kier_h_all, 'METER_DATE')\n",
    "\n",
    "    df_kier_h_c0 = pd.merge(df_kier_h_c0, df_ASOS, how = 'left', on = ['METER_DATE'])\n",
    "    df_kier_h_c0 = com_KMA.Interpolate_KMA_ASOS(df_kier_h_c0)\n",
    "    df_kier_h_c0 = com_date.create_col_ymdhm(df_kier_h_c0, 'METER_DATE')\n",
    "\n",
    "    df_kier_h_c1 = pd.merge(df_kier_h_c1, df_ASOS, how = 'left', on = ['METER_DATE'])\n",
    "    df_kier_h_c1 = com_KMA.Interpolate_KMA_ASOS(df_kier_h_c1)\n",
    "    df_kier_h_c1 = com_date.create_col_ymdhm(df_kier_h_c1, 'METER_DATE')\n",
    "\n",
    "    if K == 3:\n",
    "        df_kier_h_c2 = pd.merge(df_kier_h_c2, df_ASOS, how = 'left', on = ['METER_DATE'])\n",
    "        df_kier_h_c2 = com_KMA.Interpolate_KMA_ASOS(df_kier_h_c2)\n",
    "        df_kier_h_c2 = com_date.create_col_ymdhm(df_kier_h_c2, 'METER_DATE')\n",
    "\n",
    "    ## 모든 세대\n",
    "    if int_grp == 0 : df_tar_res = df_kier_h_all.drop(columns = ['METER_DATE', 'DAY']).dropna()\n",
    "    ## 군집 C0\n",
    "    elif int_grp == 1 : df_tar_res = df_kier_h_c0.drop(columns = ['METER_DATE', 'DAY']).dropna()\n",
    "    ## 군집 C1\n",
    "    elif int_grp == 2 : df_tar_res = df_kier_h_c1.drop(columns = ['METER_DATE', 'DAY']).dropna()\n",
    "    ## 군집 C0\n",
    "    elif int_grp == 3 : df_tar_res = df_kier_h_c2.drop(columns = ['METER_DATE', 'DAY']).dropna()\n",
    "\n",
    "    str_col_tar = str_domain + '_INST_SUM_' + dict_grp[int_grp]\n",
    "\n",
    "    return df_tar_res, str_col_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Dataset\n",
    "def buildDataSet(traindata, testdata, seqLength):\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "\n",
    "    for i in range(len(traindata)-seqLength+1):\n",
    "        tx = traindata.iloc[i:i+seqLength]\n",
    "        ty = testdata.iloc[i+seqLength-1]\n",
    "        xdata.append(tx)\n",
    "        ydata.append(ty)\n",
    "\n",
    "    return np.array(xdata), np.array(ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_model(input_shape):\n",
    "    model_input = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # for feature extracting\n",
    "    conv1 = tf.keras.layers.Conv1D(64, 1, activation='swish')(model_input)\n",
    "    pool1 = tf.keras.layers.MaxPool1D(pool_size=2, strides=1, padding='same')(conv1)\n",
    "    bat01 = tf.keras.layers.BatchNormalization()(pool1)\n",
    "    conv2 = tf.keras.layers.Conv1D(32, 1, activation='swish')(bat01)\n",
    "    pool2 = tf.keras.layers.MaxPool1D(pool_size=2, strides=1, padding='same')(conv2)\n",
    "    bat02 = tf.keras.layers.BatchNormalization()(pool2)\n",
    "\n",
    "    # 인코더 - 디코더 선언\n",
    "    encoder_lstm1 = tf.keras.layers.LSTM(16, return_sequences=True, activation='swish')\n",
    "    encoder_lstm2 = tf.keras.layers.LSTM(32, return_sequences=True, activation='swish')\n",
    "    encoder_lstm3 = tf.keras.layers.LSTM(64, return_state=True, return_sequences=True, activation='swish')\n",
    "\n",
    "    decoder_lstm1 = tf.keras.layers.LSTM(64, return_sequences=True, activation='swish')\n",
    "    decoder_lstm2 = tf.keras.layers.LSTM(32, return_sequences=True, activation='swish')\n",
    "    decoder_lstm3 = tf.keras.layers.LSTM(16, return_sequences=True, activation='swish')\n",
    "\n",
    "    # 인코더\n",
    "    encoder_output_lstm1 = encoder_lstm1(bat02)\n",
    "    encoder_output_lstm2 = encoder_lstm2(bat01)\n",
    "    encoder_output_lstm4, state_h, state_c = encoder_lstm3(encoder_output_lstm2)\n",
    "\n",
    "    #디코더\n",
    "    decoder_lstm1_output = decoder_lstm1(encoder_output_lstm4, initial_state=[state_h, state_c])\n",
    "    decoder_lstm2_output = decoder_lstm2(decoder_lstm1_output)\n",
    "    decoder_lstm3_output = decoder_lstm3(decoder_lstm2_output)\n",
    "\n",
    "    flatten = tf.keras.layers.Flatten()(decoder_lstm3_output)\n",
    "    model_output = tf.keras.layers.Dense(1)(flatten)\n",
    "    \n",
    "    model = tf.keras.models.Model(model_input, model_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : ELEC\n",
      "str_fileRaw : KIER_RAW_ELEC_2024-06-07.csv\n",
      "str_fileRaw_hList : KIER_RAW_ELEC_2024-06-07.csv\n",
      "str_file : KIER_ELEC_INST_1W_Resampled.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h_index</th>\n",
       "      <th>target_ELEC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ELEC_INST_EFF_561-1-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ELEC_INST_EFF_561-1-2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ELEC_INST_EFF_561-1-3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ELEC_INST_EFF_561-1-4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ELEC_INST_EFF_561-2-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>ELEC_INST_EFF_563-23-2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>ELEC_INST_EFF_563-23-3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>ELEC_INST_EFF_563-23-4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>ELEC_INST_EFF_563-24-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>ELEC_INST_EFF_563-24-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>348 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    h_index  target_ELEC\n",
       "0     ELEC_INST_EFF_561-1-1            2\n",
       "1     ELEC_INST_EFF_561-1-2            2\n",
       "2     ELEC_INST_EFF_561-1-3            1\n",
       "3     ELEC_INST_EFF_561-1-4            2\n",
       "4     ELEC_INST_EFF_561-2-1            2\n",
       "..                      ...          ...\n",
       "343  ELEC_INST_EFF_563-23-2            2\n",
       "344  ELEC_INST_EFF_563-23-3            1\n",
       "345  ELEC_INST_EFF_563-23-4            0\n",
       "346  ELEC_INST_EFF_563-24-1            1\n",
       "347  ELEC_INST_EFF_563-24-2            1\n",
       "\n",
       "[348 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit \n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "\n",
    "float_rate = 0.3\n",
    "# test_size = round(len(df_tar) * float_rate)\n",
    "int_fold = 10\n",
    "\n",
    "## Dict_Domain\n",
    "## {0:\"ELEC\", 1:\"HEAT\", 2:\"WATER\", 3:\"HOT_HEAT\", 4:\"HOT_FLOW\", 99:\"GAS\"}\n",
    "## K : 2 or 3\n",
    "## {0 : '10MIN', 1 : '1H', 2 : '1D', 3 : '1W', 4 : '1M'}\n",
    "## {0 : 'ALL', 1 : 'C0', 2 : 'C1', 3 : 'C2'}\n",
    "# dict_ml_model = {0 : 'CB', 1 : 'DT', 2 : 'LGBM', 3 : 'RF', 4 : 'XGB'}\n",
    "dict_dl_model = {0 : '1D-CNN_LSTM', 1 : ''}\n",
    "dict_interval = {0 : '10MIN', 1 : '1H', 2 : '1D', 3 : '1W', 4 : '1M'}\n",
    "dict_grp = {0 : 'ALL', 1 : 'C0', 2 : 'C1', 3 : 'C2'}\n",
    "int_domain, int_grp = 0, 1\n",
    "\n",
    "K = 3 ## 2, 3\n",
    "int_interval = 3 ## 3, 4\n",
    "int_model = 0 ## 0, 1, 2, 3, 4\n",
    "\n",
    "## Domain, ACCU/INST Column\n",
    "str_domain, str_col_accu, str_col_inst = com_KIER_M02.create_domain_str(int_domain)\n",
    "## Directory Root\n",
    "str_dirData, str_dir_raw, str_dir_cleansed, str_dirName_bld, str_dirName_h = com_KIER_M02.create_dir_str(str_domain)\n",
    "## Interval, Target File\n",
    "str_interval, str_fileRaw, str_fileRaw_hList, str_file = com_KIER_M02.create_file_str(str_domain, int_interval)\n",
    "\n",
    "# print(str(os.listdir(str_dirData)) + \"\\n\")\n",
    "# print(os.listdir(str_dirName_h))\n",
    "\n",
    "str_file_clustering = 'KIER_' + str(str_domain) + '_Labeled_' + str_interval + '_K' + str(K) + '.csv'\n",
    "df_kier_h_cluster = pd.read_csv(str_dirName_h + str_file_clustering\n",
    "                                , index_col = 0).rename(columns = {'index' : 'h_index'})[['h_index', 'target_' + str_domain]]\n",
    "df_kier_h_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 비군집화 데이터셋에 대한 별도 처리 (비교군)\n",
    "sys.stdout.flush() ## flush\n",
    "df_tar, str_col_tar = load_dataset_Not_cluster()\n",
    "seqLength = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Split\n",
    "trainSet_Origin, testSet_Origin = train_test_split(df_tar, test_size = float_rate, shuffle = False)\n",
    "\n",
    "trainSet, testSet = trainSet_Origin, testSet_Origin\n",
    "\n",
    "## Input / Target Split\n",
    "trainXX, trainYY = trainSet.drop([str_col_tar],axis=1), trainSet[[str_col_tar]]\n",
    "testXX, testYY = testSet.drop([str_col_tar],axis=1), testSet[[str_col_tar]]\n",
    "\n",
    "trainXXindex, trainYYindex = trainXX.index, trainYY.index\n",
    "trainXXcolumns, trainYYcolumns = trainXX.columns, trainYY.columns\n",
    "\n",
    "testXXindex, testYYindex = testXX.index, testYY.index\n",
    "testXXcolumns, testYYcolumns = testXX.columns, testYY.columns\n",
    "\n",
    "d_trainXX, d_trainYY = pd.DataFrame(trainXX, index=trainXXindex, columns=trainXXcolumns), trainYY\n",
    "\n",
    "d_testXX, d_testYY = pd.DataFrame(testXX, index=testXXindex, columns=testXXcolumns), testYY\n",
    "\n",
    "## Build Dataset\n",
    "trainX, trainY = buildDataSet(trainXX, trainYY, seqLength)\n",
    "testX, testY = buildDataSet(testXX, testYY, seqLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainXXcolumns = trainXX.columns\n",
    "int_len_col_input = len(trainXXcolumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "## SeqLength 초기값 : 24\n",
    "str_model, model = com_DL.buildModel_KIERM02_1DCNNSeq2Seq(input_shape=(seqLength, int_len_col_input))\n",
    "# d_actual, model_preds, tm_code = com_DL.model_dl_predict_KIERM02(trainX, trainY, testX, testY, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 임시조치\n",
    "# ## ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
    "# cnt_negative = 0\n",
    "# for i in range(0, len(model_preds)) : \n",
    "#     if model_preds[i] < 0 : \n",
    "#         model_preds[i] = model_preds[i] * -1\n",
    "#         cnt_negative = cnt_negative + 1\n",
    "\n",
    "# for i in range(0, len(model_preds)) : \n",
    "#     if model_preds[i] < 0 : print(model_preds[i])\n",
    "\n",
    "# if cnt_negative != 0 : print(cnt_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_scores = com_DL.model_sk_metrics(d_actual, model_preds)\n",
    "# list_scores.append(tm_code)\n",
    "\n",
    "# print(list_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "361/361 [==============================] - 78s 208ms/step - loss: 114155.9297 - mae: 215.6941\n",
      "Epoch 2/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 138621.8750 - mae: 231.5616\n",
      "Epoch 3/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 156234.9844 - mae: 241.1462\n",
      "Epoch 4/500\n",
      "361/361 [==============================] - 76s 209ms/step - loss: 142245.6719 - mae: 233.1322\n",
      "Epoch 5/500\n",
      "254/361 [====================>.........] - ETA: 22s - loss: 173692.1719 - mae: 251.4321"
     ]
    }
   ],
   "source": [
    "## 비군집화 데이터셋에 대한 별도 처리 (비교군)\n",
    "sys.stdout.flush() ## flush\n",
    "df_tar, str_col_tar = load_dataset_Not_cluster()\n",
    "## Non-Shuffle\n",
    "# list_res, list_hists = com_DL.model_dl_analysis_with_KFold(df_tar, float_rate, model, str_col_tar, int_fold, seqLength)\n",
    "## Shuffle\n",
    "list_res, list_hists = com_DL.model_dl_analysis_with_KFold(df_tar, float_rate, model, str_col_tar, int_fold, str_shuffle = True, seqLength = seqLength)\n",
    "\n",
    "## list_res 저장\n",
    "str_txt = '../kf_result_include_Clustering_' + str_model + '/kf_result_' + str(dict_interval[int_interval]) + '_ALL_' + dict_grp[int_grp] + '_' + str_model + '_CV' + str(int_fold) + '.txt'\n",
    "file_txt = open(str_txt, 'w')\n",
    "print('- Interval = ' + dict_interval[int_interval] + '\\n'\n",
    "        + '- K = 0' + '\\n'\n",
    "        + '- grp = ALL' + '\\n'\n",
    "        + '- model = ' + str_model + '\\n'\n",
    "        + '- Case = ALL' + ',' + ' size_cluster = ' + str(348) + '\\n'\n",
    "        + '- Size = ' + str(df_tar.shape) + '\\n'\n",
    "        + '- Columns = ' + str(df_tar.columns) + '\\n', file = file_txt)\n",
    "print(list_res, file = file_txt)\n",
    "\n",
    "## list_hist 저장\n",
    "str_txt = '../kf_hist_include_Clustering_' + str_model + '/kf_hist_' + str(dict_interval[int_interval]) + '_ALL_' + dict_grp[int_grp] + '_' + str_model + '_CV' + str(int_fold) + '.txt'\n",
    "file_txt = open(str_txt, 'w')\n",
    "print('- Interval = ' + dict_interval[int_interval] + '\\n'\n",
    "        + '- K = 0' + '\\n'\n",
    "        + '- grp = ALL' + '\\n'\n",
    "        + '- model = ' + str_model + '\\n'\n",
    "        + '- Case = ALL' + ',' + ' size_cluster = ' + str(348) + '\\n'\n",
    "        + '- Size = ' + str(df_tar.shape) + '\\n'\n",
    "        + '- Columns = ' + str(df_tar.columns) + '\\n', file = file_txt)\n",
    "print(list_hists, file = file_txt)\n",
    "\n",
    "## open 후 다른 것을 open하면 자동으로 close되어 저장되지만,\n",
    "## 마지막 파일은 반드시 close를 통해 종료해야만 저장이 완료됨\n",
    "file_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103, 78, 167]\n",
      "■ 1\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/500\n",
      "361/361 [==============================] - 93s 250ms/step - loss: 25487.5410 - mae: 93.1322\n",
      "Epoch 2/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 26114.2109 - mae: 96.5597\n",
      "Epoch 3/500\n",
      "361/361 [==============================] - 76s 211ms/step - loss: 20505.7793 - mae: 87.5973\n",
      "Epoch 4/500\n",
      "361/361 [==============================] - 76s 210ms/step - loss: 23279.7402 - mae: 90.5503\n",
      "Epoch 5/500\n",
      "361/361 [==============================] - 76s 210ms/step - loss: 25066.5605 - mae: 92.4702\n",
      "Epoch 6/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 19810.0781 - mae: 85.1153\n",
      "Epoch 7/500\n",
      "361/361 [==============================] - 76s 210ms/step - loss: 16286.3955 - mae: 77.9445\n",
      "Epoch 8/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 13490.0361 - mae: 69.3556\n",
      "Epoch 9/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 14742.0303 - mae: 75.3402\n",
      "Epoch 10/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 16953.0586 - mae: 80.5425\n",
      "Epoch 11/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 15414.8223 - mae: 78.5714\n",
      "Epoch 12/500\n",
      "361/361 [==============================] - 76s 210ms/step - loss: 15736.6475 - mae: 78.4497\n",
      "Epoch 13/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 9731.6152 - mae: 64.6966\n",
      "Epoch 14/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 13498.1152 - mae: 74.2238\n",
      "Epoch 15/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 14468.8711 - mae: 76.7264\n",
      "Epoch 16/500\n",
      "361/361 [==============================] - 76s 211ms/step - loss: 14778.0742 - mae: 77.0503\n",
      "Epoch 17/500\n",
      "361/361 [==============================] - 76s 210ms/step - loss: 11907.9854 - mae: 69.7874\n",
      "Epoch 18/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 12664.3066 - mae: 70.9138\n",
      "Epoch 19/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 19876.3926 - mae: 86.4707\n",
      "Epoch 20/500\n",
      "361/361 [==============================] - 75s 209ms/step - loss: 17045.0859 - mae: 81.3089\n",
      "Epoch 21/500\n",
      "361/361 [==============================] - 75s 209ms/step - loss: 18833.7109 - mae: 84.7062\n",
      "Epoch 22/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 15952.7139 - mae: 79.4706\n",
      "Epoch 23/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 12837.8359 - mae: 72.8576\n",
      "Epoch 24/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 7731.1577 - mae: 58.0936\n",
      "Epoch 25/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 7501.5518 - mae: 57.1415\n",
      "Epoch 26/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 6328.6172 - mae: 53.2782\n",
      "Epoch 27/500\n",
      "361/361 [==============================] - 75s 209ms/step - loss: 4103.0610 - mae: 45.2876\n",
      "Epoch 28/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 5361.8833 - mae: 49.7799\n",
      "Epoch 29/500\n",
      "361/361 [==============================] - 76s 210ms/step - loss: 5898.4951 - mae: 51.1555\n",
      "Epoch 30/500\n",
      "361/361 [==============================] - 76s 210ms/step - loss: 4946.3247 - mae: 48.7894\n",
      "Epoch 31/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 3883.2983 - mae: 43.3786\n",
      "Epoch 32/500\n",
      "361/361 [==============================] - 76s 211ms/step - loss: 3364.1611 - mae: 40.9088\n",
      "Epoch 33/500\n",
      "361/361 [==============================] - 76s 212ms/step - loss: 3912.8960 - mae: 43.4271\n",
      "Epoch 34/500\n",
      "361/361 [==============================] - 76s 211ms/step - loss: 4066.4756 - mae: 44.9141\n",
      "Epoch 35/500\n",
      "361/361 [==============================] - 76s 210ms/step - loss: 3145.9395 - mae: 40.6374\n",
      "Epoch 36/500\n",
      "361/361 [==============================] - 76s 210ms/step - loss: 4500.1519 - mae: 46.7244\n",
      "Epoch 37/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 6560.9673 - mae: 53.5876\n",
      "Epoch 38/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 9782.1826 - mae: 61.2555\n",
      "Epoch 39/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 5756.3657 - mae: 48.9089\n",
      "Epoch 40/500\n",
      "361/361 [==============================] - 76s 209ms/step - loss: 4172.8892 - mae: 43.4320\n",
      "Epoch 41/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 4495.4985 - mae: 45.0575\n",
      "Epoch 42/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 3758.1077 - mae: 42.2776\n",
      "Epoch 43/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 2979.9207 - mae: 39.3198\n",
      "Epoch 44/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 2151.5430 - mae: 33.9282\n",
      "Epoch 45/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 1767.5990 - mae: 31.6469\n",
      "Epoch 46/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 1809.5896 - mae: 31.9073\n",
      "Epoch 47/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 1710.9069 - mae: 31.1921\n",
      "Epoch 48/500\n",
      "361/361 [==============================] - 75s 209ms/step - loss: 1714.7108 - mae: 31.4320\n",
      "Epoch 49/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 1233.0096 - mae: 27.3709\n",
      "Epoch 50/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 1302.8800 - mae: 27.8564\n",
      "Epoch 51/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 1342.1710 - mae: 27.9322\n",
      "Epoch 52/500\n",
      "361/361 [==============================] - 75s 209ms/step - loss: 1563.5234 - mae: 30.2911\n",
      "Epoch 53/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 1362.7969 - mae: 28.3956\n",
      "Epoch 54/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 1419.4138 - mae: 28.1674\n",
      "Epoch 55/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 953.4457 - mae: 24.6884\n",
      "Epoch 56/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 1563.2341 - mae: 29.5855\n",
      "Epoch 57/500\n",
      "361/361 [==============================] - 76s 210ms/step - loss: 1363.0370 - mae: 27.7765\n",
      "Epoch 58/500\n",
      "361/361 [==============================] - 77s 213ms/step - loss: 1219.0720 - mae: 26.5137\n",
      "Epoch 59/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 1476.5992 - mae: 28.9950\n",
      "Epoch 60/500\n",
      "361/361 [==============================] - 76s 211ms/step - loss: 1110.5522 - mae: 25.7272\n",
      "Epoch 61/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 813.3064 - mae: 22.6605\n",
      "Epoch 62/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 930.8461 - mae: 23.9563\n",
      "Epoch 63/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 722.0298 - mae: 21.8938\n",
      "Epoch 64/500\n",
      "361/361 [==============================] - 75s 209ms/step - loss: 585.5905 - mae: 19.7890\n",
      "Epoch 65/500\n",
      "361/361 [==============================] - 76s 210ms/step - loss: 603.9780 - mae: 19.8610\n",
      "Epoch 66/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 551.4965 - mae: 19.1043\n",
      "Epoch 67/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 512.7611 - mae: 18.3296\n",
      "Epoch 68/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 495.4094 - mae: 18.0155\n",
      "Epoch 69/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 537.8757 - mae: 18.6126\n",
      "Epoch 70/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 567.4110 - mae: 19.2691\n",
      "Epoch 71/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 578.0612 - mae: 19.1847\n",
      "Epoch 72/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 751.9486 - mae: 21.4464\n",
      "Epoch 73/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 1052.4974 - mae: 22.5564\n",
      "Epoch 74/500\n",
      "361/361 [==============================] - 75s 206ms/step - loss: 1290.0594 - mae: 24.9251\n",
      "Epoch 75/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 826.4964 - mae: 21.8495\n",
      "Epoch 76/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 875.4768 - mae: 21.4830\n",
      "Epoch 77/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 876.1986 - mae: 21.0819\n",
      "Epoch 78/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 899.1857 - mae: 19.9935\n",
      "Epoch 79/500\n",
      "361/361 [==============================] - 75s 206ms/step - loss: 792.7568 - mae: 20.7245\n",
      "Epoch 80/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 805.3450 - mae: 20.4573\n",
      "Epoch 81/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 639.4179 - mae: 19.2563\n",
      "Epoch 82/500\n",
      "361/361 [==============================] - 75s 206ms/step - loss: 609.2097 - mae: 18.6107\n",
      "Epoch 83/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 708.0037 - mae: 19.0676\n",
      "155/155 [==============================] - 7s 46ms/step\n",
      "Epoch 1/500\n",
      "361/361 [==============================] - 77s 206ms/step - loss: 1341.8585 - mae: 20.8087\n",
      "Epoch 2/500\n",
      "361/361 [==============================] - 75s 209ms/step - loss: 579.1264 - mae: 17.5907\n",
      "Epoch 3/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 528.0814 - mae: 17.4634\n",
      "Epoch 4/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 488.7318 - mae: 16.8087\n",
      "Epoch 5/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 446.6952 - mae: 16.1387\n",
      "Epoch 6/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 450.8216 - mae: 16.1355\n",
      "Epoch 7/500\n",
      "361/361 [==============================] - 75s 206ms/step - loss: 460.3860 - mae: 16.3794\n",
      "Epoch 8/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 487.2886 - mae: 16.6850\n",
      "Epoch 9/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 412.8849 - mae: 15.2336\n",
      "Epoch 10/500\n",
      "361/361 [==============================] - 75s 209ms/step - loss: 406.3076 - mae: 15.4721\n",
      "Epoch 11/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 435.6414 - mae: 15.7183\n",
      "Epoch 12/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 398.1455 - mae: 15.2463\n",
      "Epoch 13/500\n",
      "361/361 [==============================] - 75s 209ms/step - loss: 366.1096 - mae: 14.3555\n",
      "Epoch 14/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 342.6817 - mae: 13.9121\n",
      "Epoch 15/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 350.6676 - mae: 14.4503\n",
      "Epoch 16/500\n",
      "361/361 [==============================] - 76s 209ms/step - loss: 372.8807 - mae: 14.8869\n",
      "Epoch 17/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 400.8450 - mae: 14.7740\n",
      "Epoch 18/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 418.8292 - mae: 14.8522\n",
      "Epoch 19/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 331.9781 - mae: 13.7630\n",
      "Epoch 20/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 240.9132 - mae: 11.6972\n",
      "Epoch 21/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 248.3470 - mae: 11.0714\n",
      "Epoch 22/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 253.7014 - mae: 11.7141\n",
      "Epoch 23/500\n",
      "361/361 [==============================] - 75s 206ms/step - loss: 263.1831 - mae: 11.8612\n",
      "Epoch 24/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 281.0384 - mae: 12.5261\n",
      "Epoch 25/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 280.7070 - mae: 12.7071\n",
      "Epoch 26/500\n",
      "361/361 [==============================] - 75s 209ms/step - loss: 305.2800 - mae: 13.2177\n",
      "Epoch 27/500\n",
      "361/361 [==============================] - 75s 209ms/step - loss: 299.9789 - mae: 13.4281\n",
      "Epoch 28/500\n",
      "361/361 [==============================] - 75s 209ms/step - loss: 322.6772 - mae: 13.4167\n",
      "Epoch 29/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 398.6172 - mae: 14.4884\n",
      "Epoch 30/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 364.1958 - mae: 14.2715\n",
      "Epoch 31/500\n",
      "361/361 [==============================] - 75s 206ms/step - loss: 285.4613 - mae: 12.7133\n",
      "Epoch 32/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 295.8405 - mae: 13.1444\n",
      "Epoch 33/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 280.8659 - mae: 12.8124\n",
      "Epoch 34/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 274.5805 - mae: 12.7743\n",
      "Epoch 35/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 291.1437 - mae: 13.2386\n",
      "155/155 [==============================] - 7s 46ms/step\n",
      "Epoch 1/500\n",
      "361/361 [==============================] - 77s 205ms/step - loss: 337.5223 - mae: 13.8113\n",
      "Epoch 2/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 291.0473 - mae: 13.1250\n",
      "Epoch 3/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 262.3027 - mae: 12.4240\n",
      "Epoch 4/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 279.6008 - mae: 12.9537\n",
      "Epoch 5/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 305.1464 - mae: 13.5083\n",
      "Epoch 6/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 299.9922 - mae: 13.6022\n",
      "Epoch 7/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 307.3635 - mae: 13.6740\n",
      "Epoch 8/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 319.0502 - mae: 13.9227\n",
      "Epoch 9/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 314.2441 - mae: 13.7967\n",
      "Epoch 10/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 304.9318 - mae: 13.7414\n",
      "Epoch 11/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 344.4604 - mae: 14.4274\n",
      "Epoch 12/500\n",
      "361/361 [==============================] - 77s 214ms/step - loss: 371.0917 - mae: 14.9466\n",
      "Epoch 13/500\n",
      "361/361 [==============================] - 78s 217ms/step - loss: 355.7680 - mae: 14.4111\n",
      "Epoch 14/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 360.5612 - mae: 14.8476\n",
      "Epoch 15/500\n",
      "361/361 [==============================] - 76s 210ms/step - loss: 355.3610 - mae: 14.5152\n",
      "Epoch 16/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 339.4870 - mae: 13.7303\n",
      "Epoch 17/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 303.9677 - mae: 13.5443\n",
      "Epoch 18/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 439.6653 - mae: 13.3694\n",
      "155/155 [==============================] - 8s 47ms/step\n",
      "Epoch 1/500\n",
      "361/361 [==============================] - 76s 205ms/step - loss: 429.2667 - mae: 14.3302\n",
      "Epoch 2/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 347.1030 - mae: 13.3708\n",
      "Epoch 3/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 458.5942 - mae: 13.5460\n",
      "Epoch 4/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 293.5947 - mae: 13.2018\n",
      "Epoch 5/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 313.5528 - mae: 13.3853\n",
      "Epoch 6/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 311.0313 - mae: 13.1195\n",
      "Epoch 7/500\n",
      "361/361 [==============================] - 75s 209ms/step - loss: 608.8829 - mae: 13.9075\n",
      "Epoch 8/500\n",
      "361/361 [==============================] - 76s 211ms/step - loss: 294.2746 - mae: 13.0303\n",
      "Epoch 9/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 288.9216 - mae: 12.9766\n",
      "Epoch 10/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 1151.7227 - mae: 13.1822\n",
      "Epoch 11/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 1058.8391 - mae: 13.3081\n",
      "Epoch 12/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 306.1245 - mae: 13.2749\n",
      "Epoch 13/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 733.5356 - mae: 12.9364\n",
      "Epoch 14/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 330.0441 - mae: 12.9782\n",
      "Epoch 15/500\n",
      "361/361 [==============================] - 75s 209ms/step - loss: 378.6685 - mae: 12.2902\n",
      "Epoch 16/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 387.3644 - mae: 12.8042\n",
      "Epoch 17/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 1271.2644 - mae: 14.4633\n",
      "Epoch 18/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 482.0533 - mae: 13.7281\n",
      "Epoch 19/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 502.3042 - mae: 13.6729\n",
      "Epoch 20/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 904.0785 - mae: 13.6646\n",
      "Epoch 21/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 301.3378 - mae: 12.6177\n",
      "Epoch 22/500\n",
      "361/361 [==============================] - 76s 210ms/step - loss: 485.7815 - mae: 12.9724\n",
      "Epoch 23/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 332.3993 - mae: 12.4235\n",
      "Epoch 24/500\n",
      "361/361 [==============================] - 76s 210ms/step - loss: 759.6388 - mae: 12.8784\n",
      "155/155 [==============================] - 8s 49ms/step\n",
      "Epoch 1/500\n",
      "361/361 [==============================] - 79s 211ms/step - loss: 507.7385 - mae: 13.5581\n",
      "Epoch 2/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 321.6759 - mae: 12.4615\n",
      "Epoch 3/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 271.2223 - mae: 11.3603\n",
      "Epoch 4/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 534.8791 - mae: 13.6566\n",
      "Epoch 5/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 360.8310 - mae: 11.3681\n",
      "Epoch 6/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 514.2743 - mae: 11.8955\n",
      "Epoch 7/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 407.3148 - mae: 11.4924\n",
      "Epoch 8/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 341.4271 - mae: 11.2976\n",
      "Epoch 9/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 1731.2930 - mae: 12.0755\n",
      "Epoch 10/500\n",
      "361/361 [==============================] - 77s 212ms/step - loss: 629.9269 - mae: 12.0522\n",
      "Epoch 11/500\n",
      "361/361 [==============================] - 76s 210ms/step - loss: 311.2169 - mae: 12.0199\n",
      "Epoch 12/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 274.4254 - mae: 11.6440\n",
      "Epoch 13/500\n",
      "361/361 [==============================] - 77s 213ms/step - loss: 298.7376 - mae: 11.6092\n",
      "Epoch 14/500\n",
      "361/361 [==============================] - 76s 211ms/step - loss: 525.3868 - mae: 12.0487\n",
      "Epoch 15/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 538.2699 - mae: 11.7462\n",
      "Epoch 16/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 233.7182 - mae: 11.1670\n",
      "Epoch 17/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 244.3815 - mae: 11.3251\n",
      "Epoch 18/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 276.4926 - mae: 11.0968\n",
      "Epoch 19/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 229.0530 - mae: 11.1552\n",
      "Epoch 20/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 400.3940 - mae: 10.9893\n",
      "Epoch 21/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 228.6139 - mae: 11.0462\n",
      "Epoch 22/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 247.8716 - mae: 10.7671\n",
      "Epoch 23/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 195.0027 - mae: 10.4326\n",
      "Epoch 24/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 191.0420 - mae: 10.2785\n",
      "Epoch 25/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 205.8271 - mae: 10.3290\n",
      "Epoch 26/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 184.3912 - mae: 9.9639\n",
      "Epoch 27/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 175.4855 - mae: 9.7803\n",
      "Epoch 28/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 180.3497 - mae: 9.7923\n",
      "Epoch 29/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 231.8428 - mae: 10.0565\n",
      "Epoch 30/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 188.7529 - mae: 10.1404\n",
      "Epoch 31/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 175.6096 - mae: 9.6041\n",
      "Epoch 32/500\n",
      "361/361 [==============================] - 75s 208ms/step - loss: 209.7859 - mae: 9.7957\n",
      "Epoch 33/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 197.1908 - mae: 9.8934\n",
      "Epoch 34/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 303.9449 - mae: 9.6732\n",
      "Epoch 35/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 215.9269 - mae: 9.4167\n",
      "Epoch 36/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 268.1896 - mae: 9.5169\n",
      "Epoch 37/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 256.0853 - mae: 9.4801\n",
      "Epoch 38/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 160.0283 - mae: 9.1885\n",
      "Epoch 39/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 165.1328 - mae: 9.3938\n",
      "Epoch 40/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 167.6414 - mae: 9.2135\n",
      "Epoch 41/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 166.6539 - mae: 9.2467\n",
      "Epoch 42/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 159.1901 - mae: 9.2147\n",
      "Epoch 43/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 153.1365 - mae: 9.0819\n",
      "Epoch 44/500\n",
      "361/361 [==============================] - 75s 206ms/step - loss: 155.2980 - mae: 9.0322\n",
      "Epoch 45/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 168.3577 - mae: 9.1971\n",
      "Epoch 46/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 208.1640 - mae: 9.1242\n",
      "Epoch 47/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 202.7608 - mae: 9.4092\n",
      "Epoch 48/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 192.7495 - mae: 9.1848\n",
      "Epoch 49/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 187.0862 - mae: 9.3615\n",
      "Epoch 50/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 174.3362 - mae: 9.6068\n",
      "Epoch 51/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 178.9988 - mae: 9.6544\n",
      "Epoch 52/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 175.1783 - mae: 9.5745\n",
      "Epoch 53/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 184.4311 - mae: 9.5643\n",
      "Epoch 54/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 169.8215 - mae: 9.4605\n",
      "Epoch 55/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 211.2527 - mae: 9.5685\n",
      "Epoch 56/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 331.0947 - mae: 9.7840\n",
      "Epoch 57/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 176.0452 - mae: 9.5901\n",
      "Epoch 58/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 173.3132 - mae: 9.5018\n",
      "155/155 [==============================] - 7s 47ms/step\n",
      "Epoch 1/500\n",
      "361/361 [==============================] - 76s 204ms/step - loss: 184.4415 - mae: 9.7479\n",
      "Epoch 2/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 167.5992 - mae: 9.3778\n",
      "Epoch 3/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 171.7813 - mae: 9.1823\n",
      "Epoch 4/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 164.5920 - mae: 9.1142\n",
      "Epoch 5/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 157.4985 - mae: 9.1611\n",
      "Epoch 6/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 175.8624 - mae: 9.1531\n",
      "Epoch 7/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 167.4918 - mae: 9.3081\n",
      "Epoch 8/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 188.6570 - mae: 9.4665\n",
      "Epoch 9/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 166.6030 - mae: 9.1909\n",
      "Epoch 10/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 281.8204 - mae: 9.6366\n",
      "Epoch 11/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 1153.2030 - mae: 9.6001\n",
      "Epoch 12/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 172.7487 - mae: 9.4463\n",
      "Epoch 13/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 163.0994 - mae: 9.0962\n",
      "Epoch 14/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 175.2686 - mae: 9.1407\n",
      "Epoch 15/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 158.2487 - mae: 9.1751\n",
      "Epoch 16/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 174.4230 - mae: 9.1216\n",
      "Epoch 17/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 164.9608 - mae: 9.0982\n",
      "Epoch 18/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 233.3288 - mae: 9.3062\n",
      "Epoch 19/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 837.6175 - mae: 9.5379\n",
      "Epoch 20/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 163.1008 - mae: 9.1204\n",
      "155/155 [==============================] - 7s 46ms/step\n",
      "Epoch 1/500\n",
      "361/361 [==============================] - 76s 204ms/step - loss: 180.8075 - mae: 9.2177\n",
      "Epoch 2/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 142.9348 - mae: 8.7342\n",
      "Epoch 3/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 148.2677 - mae: 8.8084\n",
      "Epoch 4/500\n",
      "361/361 [==============================] - 73s 204ms/step - loss: 196.3233 - mae: 9.1151\n",
      "Epoch 5/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 166.4828 - mae: 8.8785\n",
      "Epoch 6/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 563.3211 - mae: 9.0383\n",
      "Epoch 7/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 143.0827 - mae: 8.7290\n",
      "Epoch 8/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 3220.4065 - mae: 9.1805\n",
      "Epoch 9/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 138.9869 - mae: 8.5173\n",
      "Epoch 10/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 141.7100 - mae: 8.5499\n",
      "Epoch 11/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 204.5338 - mae: 8.6325\n",
      "Epoch 12/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 134.2679 - mae: 8.4580\n",
      "Epoch 13/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 138.4612 - mae: 8.5400\n",
      "Epoch 14/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 196.7477 - mae: 8.7524\n",
      "Epoch 15/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 162.9444 - mae: 8.5231\n",
      "Epoch 16/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 195.0851 - mae: 8.5475\n",
      "Epoch 17/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 139.2577 - mae: 8.4759\n",
      "Epoch 18/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 144.2348 - mae: 8.5509\n",
      "Epoch 19/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 147.2968 - mae: 8.4968\n",
      "Epoch 20/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 145.0545 - mae: 8.4967\n",
      "Epoch 21/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 133.0736 - mae: 8.3712\n",
      "Epoch 22/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 209.7119 - mae: 8.5467\n",
      "Epoch 23/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 136.5083 - mae: 8.4118\n",
      "Epoch 24/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 131.7884 - mae: 8.3682\n",
      "Epoch 25/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 141.5877 - mae: 8.4776\n",
      "Epoch 26/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 139.0697 - mae: 8.5146\n",
      "Epoch 27/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 146.7062 - mae: 8.4930\n",
      "Epoch 28/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 158.9320 - mae: 8.5642\n",
      "Epoch 29/500\n",
      "361/361 [==============================] - 75s 209ms/step - loss: 1091.8876 - mae: 8.7202\n",
      "Epoch 30/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 434.2695 - mae: 8.7890\n",
      "Epoch 31/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 183.8988 - mae: 8.5412\n",
      "Epoch 32/500\n",
      "361/361 [==============================] - 74s 205ms/step - loss: 789.3141 - mae: 8.7354\n",
      "Epoch 33/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 417.2356 - mae: 8.6275\n",
      "Epoch 34/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 134.3425 - mae: 8.4248\n",
      "Epoch 35/500\n",
      "361/361 [==============================] - 75s 209ms/step - loss: 134.9007 - mae: 8.4277\n",
      "Epoch 36/500\n",
      "361/361 [==============================] - 76s 209ms/step - loss: 151.3695 - mae: 8.3630\n",
      "Epoch 37/500\n",
      "361/361 [==============================] - 74s 206ms/step - loss: 128.0789 - mae: 8.2526\n",
      "Epoch 38/500\n",
      "361/361 [==============================] - 75s 207ms/step - loss: 1797.7173 - mae: 8.6364\n",
      "Epoch 39/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 132.4780 - mae: 8.2587\n",
      "Epoch 40/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 161.0282 - mae: 8.4256\n",
      "Epoch 41/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 359.1692 - mae: 8.6524\n",
      "Epoch 42/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 132.6828 - mae: 8.3656\n",
      "Epoch 43/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 165.0175 - mae: 8.4386\n",
      "Epoch 44/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 770.1930 - mae: 8.7362\n",
      "Epoch 45/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 131.9454 - mae: 8.3476\n",
      "Epoch 46/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 130.5602 - mae: 8.2839\n",
      "Epoch 47/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 131.5586 - mae: 8.3107\n",
      "Epoch 48/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 375.4974 - mae: 8.4319\n",
      "Epoch 49/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 130.1102 - mae: 8.2720\n",
      "Epoch 50/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 128.3951 - mae: 8.2603\n",
      "Epoch 51/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 130.7122 - mae: 8.3261\n",
      "Epoch 52/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 149.3218 - mae: 8.3202\n",
      "155/155 [==============================] - 7s 46ms/step\n",
      "Epoch 1/500\n",
      "361/361 [==============================] - 75s 202ms/step - loss: 148.0965 - mae: 8.4230\n",
      "Epoch 2/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 136.7491 - mae: 8.4523\n",
      "Epoch 3/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 130.9845 - mae: 8.3875\n",
      "Epoch 4/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 135.1921 - mae: 8.4267\n",
      "Epoch 5/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 133.1212 - mae: 8.4143\n",
      "Epoch 6/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 129.5324 - mae: 8.3167\n",
      "Epoch 7/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 216.9953 - mae: 8.3946\n",
      "Epoch 8/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 129.2628 - mae: 8.3062\n",
      "Epoch 9/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 130.1665 - mae: 8.3012\n",
      "Epoch 10/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 126.3052 - mae: 8.2376\n",
      "Epoch 11/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 128.8254 - mae: 8.2467\n",
      "Epoch 12/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 123.6490 - mae: 8.1414\n",
      "Epoch 13/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 123.8809 - mae: 8.1202\n",
      "Epoch 14/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 130.2950 - mae: 8.2863\n",
      "Epoch 15/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 126.3412 - mae: 8.2209\n",
      "Epoch 16/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 120.9945 - mae: 8.0837\n",
      "Epoch 17/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 114.5759 - mae: 8.0167\n",
      "Epoch 18/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 95.6855 - mae: 7.4655\n",
      "Epoch 19/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 92.0934 - mae: 7.3839\n",
      "Epoch 20/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 88.6828 - mae: 7.1771\n",
      "Epoch 21/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 297.2220 - mae: 7.4226\n",
      "Epoch 22/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 76.5395 - mae: 6.7989\n",
      "Epoch 23/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 74.9161 - mae: 6.7211\n",
      "Epoch 24/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 73.2466 - mae: 6.6085\n",
      "Epoch 25/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 82.6177 - mae: 6.6510\n",
      "Epoch 26/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 81.8072 - mae: 6.7976\n",
      "Epoch 27/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 65.4944 - mae: 6.2175\n",
      "Epoch 28/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 58.1120 - mae: 5.9065\n",
      "Epoch 29/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 58.0473 - mae: 5.8900\n",
      "Epoch 30/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 64.0406 - mae: 6.1656\n",
      "Epoch 31/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 83.9070 - mae: 6.8230\n",
      "Epoch 32/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 75.4547 - mae: 6.6582\n",
      "Epoch 33/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 11342.4434 - mae: 7.3938\n",
      "Epoch 34/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 56.3778 - mae: 5.8475\n",
      "Epoch 35/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 53.5392 - mae: 5.6938\n",
      "Epoch 36/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 51.5191 - mae: 5.5322\n",
      "Epoch 37/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 50.0634 - mae: 5.4335\n",
      "Epoch 38/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 75.8447 - mae: 6.4655\n",
      "Epoch 39/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 64.0197 - mae: 6.0266\n",
      "Epoch 40/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 57.6473 - mae: 5.8441\n",
      "Epoch 41/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 144.1040 - mae: 6.6072\n",
      "Epoch 42/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 58.9541 - mae: 5.9949\n",
      "Epoch 43/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 83.8328 - mae: 6.7043\n",
      "Epoch 44/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 78.1909 - mae: 6.5562\n",
      "Epoch 45/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 88.4042 - mae: 6.8718\n",
      "Epoch 46/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 74.6571 - mae: 6.4766\n",
      "Epoch 47/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 56.4046 - mae: 5.7884\n",
      "Epoch 48/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 48.6734 - mae: 5.4311\n",
      "Epoch 49/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 44.8060 - mae: 5.1848\n",
      "Epoch 50/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 46.7386 - mae: 5.2619\n",
      "Epoch 51/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 59.4212 - mae: 5.7128\n",
      "Epoch 52/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 117.3323 - mae: 7.7675\n",
      "Epoch 53/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 881.2288 - mae: 7.7154\n",
      "Epoch 54/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 81.8545 - mae: 6.6512\n",
      "Epoch 55/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 80.4165 - mae: 6.6264\n",
      "Epoch 56/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 68.0726 - mae: 6.2501\n",
      "Epoch 57/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 62.7524 - mae: 6.1151\n",
      "Epoch 58/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 94.5843 - mae: 6.4212\n",
      "Epoch 59/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 3825.6946 - mae: 6.5231\n",
      "Epoch 60/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 56.9013 - mae: 5.7667\n",
      "Epoch 61/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 60.5586 - mae: 5.9881\n",
      "Epoch 62/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 57.1213 - mae: 5.8348\n",
      "Epoch 63/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 55.5328 - mae: 5.6618\n",
      "Epoch 64/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 699.1490 - mae: 6.5262\n",
      "155/155 [==============================] - 7s 46ms/step\n",
      "Epoch 1/500\n",
      "361/361 [==============================] - 75s 202ms/step - loss: 60.9217 - mae: 5.8095\n",
      "Epoch 2/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 52.2363 - mae: 5.4889\n",
      "Epoch 3/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 48.6901 - mae: 5.3143\n",
      "Epoch 4/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 152.8595 - mae: 6.2252\n",
      "Epoch 5/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 73.1452 - mae: 6.0961\n",
      "Epoch 6/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 51.2570 - mae: 5.3641\n",
      "Epoch 7/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 75.3526 - mae: 5.3456\n",
      "Epoch 8/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 44.9322 - mae: 5.0807\n",
      "Epoch 9/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 47.2236 - mae: 5.1211\n",
      "Epoch 10/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 57.1154 - mae: 5.2782\n",
      "Epoch 11/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 100.5161 - mae: 5.1858\n",
      "Epoch 12/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 47.2020 - mae: 5.2472\n",
      "Epoch 13/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 12393.5781 - mae: 6.2832\n",
      "Epoch 14/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 48.1626 - mae: 4.9924\n",
      "Epoch 15/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 853.7477 - mae: 5.4258\n",
      "Epoch 16/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 65.5392 - mae: 4.9616\n",
      "Epoch 17/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 40.9211 - mae: 4.8828\n",
      "Epoch 18/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 43.1058 - mae: 4.9842\n",
      "Epoch 19/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 45.4961 - mae: 5.1629\n",
      "Epoch 20/500\n",
      "361/361 [==============================] - 74s 204ms/step - loss: 40.4507 - mae: 4.8454\n",
      "Epoch 21/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 42.6021 - mae: 4.9841\n",
      "Epoch 22/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 49.0210 - mae: 5.3632\n",
      "Epoch 23/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 63.3392 - mae: 6.0204\n",
      "Epoch 24/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 43.0931 - mae: 5.0546\n",
      "Epoch 25/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 44.5418 - mae: 5.1080\n",
      "Epoch 26/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 37.8814 - mae: 4.7093\n",
      "Epoch 27/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 38.7751 - mae: 4.7253\n",
      "Epoch 28/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 42.1211 - mae: 4.8503\n",
      "Epoch 29/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 46.8861 - mae: 5.1983\n",
      "Epoch 30/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 71.2267 - mae: 6.3738\n",
      "Epoch 31/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 54.7718 - mae: 5.6294\n",
      "Epoch 32/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 58.1502 - mae: 5.8481\n",
      "Epoch 33/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 56.4800 - mae: 5.8241\n",
      "Epoch 34/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 44.8819 - mae: 5.1915\n",
      "Epoch 35/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 40.5954 - mae: 4.8673\n",
      "Epoch 36/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 36.9419 - mae: 4.5903\n",
      "Epoch 37/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 292.9970 - mae: 4.7546\n",
      "Epoch 38/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 44.6474 - mae: 4.9017\n",
      "Epoch 39/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 46.5493 - mae: 4.9152\n",
      "Epoch 40/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 37.0451 - mae: 4.5420\n",
      "Epoch 41/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 40.4509 - mae: 4.7366\n",
      "Epoch 42/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 45.1317 - mae: 4.8770\n",
      "Epoch 43/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 36.6937 - mae: 4.4789\n",
      "Epoch 44/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 38.6054 - mae: 4.4959\n",
      "Epoch 45/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 56.6918 - mae: 5.0264\n",
      "Epoch 46/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 2670440.5000 - mae: 21.2572\n",
      "Epoch 47/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 68.8001 - mae: 5.0447\n",
      "Epoch 48/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 34.4375 - mae: 4.2754\n",
      "Epoch 49/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 30.8731 - mae: 4.0982\n",
      "Epoch 50/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 14185.7354 - mae: 5.6337\n",
      "Epoch 51/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 33.8459 - mae: 4.2098\n",
      "Epoch 52/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 46.5677 - mae: 4.3288\n",
      "Epoch 53/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 29.7250 - mae: 4.0354\n",
      "Epoch 54/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 103.3879 - mae: 4.6108\n",
      "Epoch 55/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 33.2980 - mae: 4.3197\n",
      "Epoch 56/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 37.5913 - mae: 4.6235\n",
      "Epoch 57/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 62.9664 - mae: 4.4569\n",
      "Epoch 58/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 39.0192 - mae: 4.6007\n",
      "Epoch 59/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 36.4781 - mae: 4.5000\n",
      "Epoch 60/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 34.7565 - mae: 4.4062\n",
      "Epoch 61/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 52.8341 - mae: 5.4016\n",
      "Epoch 62/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 79.4824 - mae: 6.7443\n",
      "Epoch 63/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 82.6096 - mae: 6.8605\n",
      "Epoch 64/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 77.8493 - mae: 6.6362\n",
      "Epoch 65/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 93.7913 - mae: 7.2733\n",
      "Epoch 66/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 110.3103 - mae: 7.8002\n",
      "Epoch 67/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 115.7202 - mae: 7.8826\n",
      "Epoch 68/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 109.1802 - mae: 7.7467\n",
      "155/155 [==============================] - 7s 46ms/step\n",
      "Epoch 1/500\n",
      "361/361 [==============================] - 76s 202ms/step - loss: 116.1200 - mae: 7.9904\n",
      "Epoch 2/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 111.2774 - mae: 7.8043\n",
      "Epoch 3/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 192.3103 - mae: 7.9633\n",
      "Epoch 4/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 126.8453 - mae: 7.6336\n",
      "Epoch 5/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 127.0641 - mae: 8.0696\n",
      "Epoch 6/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 84.7096 - mae: 6.9509\n",
      "Epoch 7/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 96.5826 - mae: 7.3850\n",
      "Epoch 8/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 76.9274 - mae: 6.5745\n",
      "Epoch 9/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 68.7056 - mae: 6.4094\n",
      "Epoch 10/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 58.3894 - mae: 5.9531\n",
      "Epoch 11/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 64.2156 - mae: 6.1953\n",
      "Epoch 12/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 2054.1365 - mae: 7.1135\n",
      "Epoch 13/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 69.7156 - mae: 6.2420\n",
      "Epoch 14/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 70.0595 - mae: 6.3729\n",
      "Epoch 15/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 58.7766 - mae: 5.8770\n",
      "Epoch 16/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 52.2717 - mae: 5.5565\n",
      "Epoch 17/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 51.7593 - mae: 5.5688\n",
      "Epoch 18/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 47.5551 - mae: 5.3257\n",
      "Epoch 19/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 44.1021 - mae: 5.1321\n",
      "Epoch 20/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 39.1518 - mae: 4.8006\n",
      "Epoch 21/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 42.8869 - mae: 4.8153\n",
      "Epoch 22/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 151.4538 - mae: 4.8295\n",
      "Epoch 23/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 42.8362 - mae: 4.9152\n",
      "Epoch 24/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 41.9188 - mae: 4.9009\n",
      "Epoch 25/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 36.0441 - mae: 4.5487\n",
      "Epoch 26/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 36.4190 - mae: 4.5003\n",
      "Epoch 27/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 35.7704 - mae: 4.4346\n",
      "Epoch 28/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 31.6094 - mae: 4.2463\n",
      "Epoch 29/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 32.7205 - mae: 4.3447\n",
      "Epoch 30/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 954.6807 - mae: 5.1261\n",
      "Epoch 31/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 39.0780 - mae: 4.7331\n",
      "Epoch 32/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 46.8374 - mae: 5.1916\n",
      "Epoch 33/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 35.8641 - mae: 4.5224\n",
      "Epoch 34/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 45.8606 - mae: 4.7938\n",
      "Epoch 35/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 50.7266 - mae: 5.2487\n",
      "Epoch 36/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 71.4098 - mae: 5.2415\n",
      "Epoch 37/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 51.7409 - mae: 5.5065\n",
      "Epoch 38/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 56.1507 - mae: 5.5345\n",
      "Epoch 39/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 57.0382 - mae: 5.8454\n",
      "Epoch 40/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 58.1371 - mae: 5.5249\n",
      "Epoch 41/500\n",
      "361/361 [==============================] - 73s 202ms/step - loss: 58.4103 - mae: 5.6331\n",
      "Epoch 42/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 60.9308 - mae: 5.7393\n",
      "Epoch 43/500\n",
      "361/361 [==============================] - 73s 203ms/step - loss: 59.0323 - mae: 5.7530\n",
      "155/155 [==============================] - 7s 46ms/step\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../kf_hist_include_Clustering_1D-CNN_Seq2Seq/kf_hist_1W_K3_Case00_C0_1D-CNN_Seq2Seq_CV10.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 63\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m## list_hist 저장\u001b[39;00m\n\u001b[0;32m     62\u001b[0m str_txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../kf_hist_include_Clustering_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m str_model \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kf_hist_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(dict_interval[int_interval]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_K\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(K)  \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_Case0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m dict_grp[int_grp] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m str_model \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_CV\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(int_fold) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 63\u001b[0m file_txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstr_txt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- Interval = \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m dict_interval[int_interval] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- K = \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(K) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- grp = C0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(int_grp) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- Size = \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(df_tar\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- Columns = \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(df_tar\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, file \u001b[38;5;241m=\u001b[39m file_txt)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(list_hists, file \u001b[38;5;241m=\u001b[39m file_txt)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\dev-ts\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../kf_hist_include_Clustering_1D-CNN_Seq2Seq/kf_hist_1W_K3_Case00_C0_1D-CNN_Seq2Seq_CV10.txt'"
     ]
    }
   ],
   "source": [
    "## 군집화 데이터셋에 대한 별도 처리\n",
    "for i in range (0, 3): ## 각 기간별 N번의 Clustering을 병행\n",
    "        sys.stdout.flush() ## flush\n",
    "        df_kier_summary_total, list_size_cluster = cluster_label()\n",
    "        print(list_size_cluster)\n",
    "        # df_kier_summary_total\n",
    "\n",
    "        for int_grp in range(1, K + 1): ## 군집 형성된 데이터셋만 분석\n",
    "                print('■ ' + str(int_grp))\n",
    "                df_tar, str_col_tar = load_dataset_cluster(int_grp) ## 해당 군집에 대한 데이터셋 및 Target Column\n",
    "                # print(df_tar.columns)\n",
    "                # print(df_tar.shape)\n",
    "                \n",
    "                ## 임시 (더 적절한 변수로 지정해야함 + 함수화 필요)\n",
    "                ## Data Split\n",
    "                trainSet_Origin, testSet_Origin = train_test_split(df_tar, test_size = float_rate, shuffle = False)\n",
    "\n",
    "                trainSet, testSet = trainSet_Origin, testSet_Origin\n",
    "\n",
    "                ## Input / Target Split\n",
    "                trainXX, trainYY = trainSet.drop([str_col_tar],axis=1), trainSet[[str_col_tar]]\n",
    "                testXX, testYY = testSet.drop([str_col_tar],axis=1), testSet[[str_col_tar]]\n",
    "\n",
    "                trainXXindex, trainYYindex = trainXX.index, trainYY.index\n",
    "                trainXXcolumns, trainYYcolumns = trainXX.columns, trainYY.columns\n",
    "\n",
    "                testXXindex, testYYindex = testXX.index, testYY.index\n",
    "                testXXcolumns, testYYcolumns = testXX.columns, testYY.columns\n",
    "\n",
    "                d_trainXX, d_trainYY = pd.DataFrame(trainXX, index=trainXXindex, columns=trainXXcolumns), trainYY\n",
    "\n",
    "                d_testXX, d_testYY = pd.DataFrame(testXX, index=testXXindex, columns=testXXcolumns), testYY\n",
    "\n",
    "                ## Build Dataset\n",
    "                trainX, trainY = buildDataSet(trainXX, trainYY, seqLength)\n",
    "                testX, testY = buildDataSet(testXX, testYY, seqLength)\n",
    "                \n",
    "                trainXXcolumns = trainXX.columns\n",
    "                int_len_col_input = len(trainXXcolumns)\n",
    "\n",
    "                # str_model, model = com_DL.buildModel_KIERM02_1DCNNLSTM(int_len_col_input)\n",
    "                str_model, model = com_DL.buildModel_KIERM02_1DCNNSeq2Seq(input_shape=(seqLength, int_len_col_input))\n",
    "\n",
    "                ## Not Shuffle\n",
    "                # list_res, list_hists = com_DL.model_dl_analysis_with_KFold(df_tar, float_rate, model, str_col_tar, int_fold, str_shuffle = False, seqLength)\n",
    "                ## Shuffle\n",
    "                list_res, list_hists = com_DL.model_dl_analysis_with_KFold(df_tar, float_rate, model, str_col_tar, int_fold, str_shuffle = True, seqLength = seqLength)\n",
    "\n",
    "                ## list_res 저장\n",
    "                str_txt = '../kf_result_include_Clustering_' + str_model + '/kf_result_' + str(dict_interval[int_interval]) + '_K'  + str(K)  + '_Case0' + str(i) + '_' + dict_grp[int_grp] + '_' + str_model + '_CV' + str(int_fold) + '.txt'\n",
    "                file_txt = open(str_txt, 'w')\n",
    "                print('- Interval = ' + dict_interval[int_interval] + '\\n'\n",
    "                        + '- K = ' + str(K) + '\\n'\n",
    "                        + '- grp = C0' + str(int_grp) + '\\n'\n",
    "                        + '- model = ' + str_model + '\\n'\n",
    "                        + '- Case = 0' + str(i) + ',' + ' size_cluster = ' + str(list_size_cluster) + '\\n'\n",
    "                        + '- Size = ' + str(df_tar.shape) + '\\n'\n",
    "                        + '- Columns = ' + str(df_tar.columns) + '\\n', file = file_txt)\n",
    "                print(list_res, file = file_txt)\n",
    "\n",
    "                ## list_hist 저장\n",
    "                str_txt = '../kf_hist_include_Clustering_' + str_model + '/kf_hist_' + str(dict_interval[int_interval]) + '_K'  + str(K)  + '_Case0' + str(i) + '_' + dict_grp[int_grp] + '_' + str_model + '_CV' + str(int_fold) + '.txt'\n",
    "                file_txt = open(str_txt, 'w')\n",
    "                print('- Interval = ' + dict_interval[int_interval] + '\\n'\n",
    "                        + '- K = ' + str(K) + '\\n'\n",
    "                        + '- grp = C0' + str(int_grp) + '\\n'\n",
    "                        + '- model = ' + str_model + '\\n'\n",
    "                        + '- Case = 0' + str(i) + ',' + ' size_cluster = ' + str(list_size_cluster) + '\\n'\n",
    "                        + '- Size = ' + str(df_tar.shape) + '\\n'\n",
    "                        + '- Columns = ' + str(df_tar.columns) + '\\n', file = file_txt)\n",
    "                print(list_hists, file = file_txt)\n",
    "\n",
    "                ## open 후 다른 것을 open하면 자동으로 close되어 저장되지만,\n",
    "                ## 마지막 파일은 반드시 close를 통해 종료해야만 저장이 완료됨           \n",
    "                file_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
