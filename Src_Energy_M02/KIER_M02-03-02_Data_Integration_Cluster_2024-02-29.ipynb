{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Hist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - CODE  \n",
    "    &ensp; : Crawling - 특일 정보 조회 (KASI)\n",
    "\n",
    "  - DATE  \n",
    "    &ensp; 2024-02-22 Created  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; 1) 사용량을 Cluster별로 분류하기 위해 생성  \n",
    "    &ensp; 2024-02-25 Updated  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; 1) 날씨 데이터 Merge 부분을 분리 및 제거 (intergration_Weather)  \n",
    "    \n",
    " - DESC  \n",
    "    &ensp; : 전처리 - 한국지역난방공사 열판매량/열공급량   \n",
    "    &emsp; 1) 결측치가 없어서, 그대로 사용  \n",
    "    &emsp;&ensp;&ensp; \n",
    "    &emsp;&ensp;&ensp; (Crawl Code 없음)   \n",
    "\n",
    " - DATA  \n",
    "    &emsp; <\"Input\">  \n",
    "    1) None (Input Dataset)  \n",
    "    &emsp;- Period :   \n",
    "    &emsp;- Interval : \n",
    "\n",
    "    &emsp; <\"Output\">  \n",
    "    1) Hourly (관측소/년도별 출력)  \n",
    "    &nbsp;df_data_cal.to_csv(data_dir + 'KASI_DATE_D_Final.csv', index = False, encoding='utf-8-sig')  \n",
    "    &emsp;- Columns : ['YEAR', 'MONTH', 'DAY'  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;, 'dateKind', 'code_day_of_the_week', 'day_of_the_week'  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;, 'rest_YN', 'name_of_holiday', 'dist_from_holiday']\n",
    "    &emsp;- Period :   \n",
    "    &emsp;- Interval :  \n",
    "    \n",
    "    2) Daily (관측소/년도별 출력)  \n",
    "    &nbsp;df_data_cal_24.to_csv(data_dir + 'KASI_DATE_H_Final.csv', index = False, encoding='utf-8-sig')  \n",
    "    &emsp;- Columns : ['locdate', 'YEAR', 'MONTH', 'DAY'  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;, 'dateKind', 'code_day_of_the_week', 'day_of_the_week'  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;, 'rest_YN', 'name_of_holiday', 'dist_from_holiday'  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;, 'HOUR', 'MINUTE']\n",
    "    &emsp;- Period :   \n",
    "    &emsp;- Interval :  \n",
    "    \n",
    "    \n",
    "\n",
    " - Related Link  \n",
    "    &ensp; : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-01. Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-01-01. Init_Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region Basic_Import\n",
    "## Basic\n",
    "import os, sys, warnings\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.path.dirname(os.path.abspath('./__file__'))\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('./__file__'))))\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "pd.options.display.float_format = '{:.10f}'.format\n",
    "\n",
    "import math, random\n",
    "\n",
    "## Datetime\n",
    "import time, datetime as dt\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "## glob\n",
    "import glob, requests, json\n",
    "from glob import glob\n",
    "\n",
    "## 시각화\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "# %matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "## Split, 정규화\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# K-Means 알고리즘\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "# Clustering 알고리즘의 성능 평가 측도\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score, silhouette_score, rand_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "## For Web\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlencode, unquote, quote_plus\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "#endregion Basic_Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import_DL\n",
    "str_tar = \"tf\"\n",
    "## For Torch\n",
    "if str_tar == \"torch\":\n",
    "    import torch, torch.nn as nn\n",
    "    from torch.nn.utils import weight_norm\n",
    "    print(\"Torch Imported\")\n",
    "## For TF\n",
    "elif str_tar == \"tf\":\n",
    "    import tensorflow as tf, tensorflow_addons as tfa\n",
    "    from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "    from keras.models import Sequential, load_model\n",
    "    from keras_flops import get_flops\n",
    "    print(\"Tensorflow Imported\")\n",
    "else:\n",
    "    print(\"Error : Cannot be used except for Keywords\")\n",
    "    print(\" : torch / tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import_Local\n",
    "from Src_Dev_Common import Data_Datetime as com_date, KMA_Weather as com_KMA, KECO_AirKor as com_KECO, KASI_Holiday as com_Holi, KIER_Usage_M02 as com_KIER_M02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-01-02. Config (Directory, Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Init_config\n",
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"], os.environ['TF_DETERMINISTIC_OPS'] = str(SEED), \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Todate str\n",
    "str_now_ymd = pd.datetime.now().date()\n",
    "str_now_y, str_now_m, str_now_d = pd.datetime.now().year, pd.datetime.now().month, pd.datetime.now().day\n",
    "str_now_hr, str_now_min = pd.datetime.now().hour, pd.datetime.now().minute\n",
    "\n",
    "print(pd.datetime.now())\n",
    "print(str(str_now_y) + \" / \" + str(str_now_m)  + \" / \" + str(str_now_d))\n",
    "print(str(str_now_hr) + \" : \" + str(str_now_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dict_Domain\n",
    "## {0:\"ELEC\", 1:\"HEAT\", 2:\"WATER\", 3:\"HOT_HEAT\", 4:\"HOT_FLOW\", 99:\"GAS\"}\n",
    "## {'10min', '1H', '1D', '1W', '1M'}\n",
    "int_domain, int_interval = 0, 4\n",
    "\n",
    "## Domain, ACCU/INST Column\n",
    "str_domain, str_col_accu, str_col_inst = com_KIER_M02.create_domain_str(int_domain)\n",
    "## Directory Root\n",
    "str_dirData, str_dir_raw, str_dir_cleansed, str_dirName_bld, str_dirName_h = com_KIER_M02.create_dir_str(str_domain)\n",
    "## Interval, Target File\n",
    "str_interval, str_fileRaw, str_fileRaw_hList, str_file = com_KIER_M02.create_file_str(str_domain, int_interval)\n",
    "\n",
    "str_file_clustering = 'KIER_' + str(str_domain) + '_Labeled_' + str_interval + '.csv'\n",
    "\n",
    "print(str(os.listdir(str_dirData)) + \"\\n\")\n",
    "print(os.listdir(str_dirName_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-02. Data Load (df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-02-01. KIER Energy Usage (Intergrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_file = 'KIER_' + str_domain + '_INST_Weather_ALL_' + str_interval + '.csv'\n",
    "df_kier_raw = pd.read_csv(str_dirName_h + str_file\n",
    "                          , index_col = 0)\n",
    "df_kier_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Date Data\n",
    "list_col_date = df_kier_raw.columns[:5].to_list()\n",
    "## Weather Data\n",
    "list_col_weather = df_kier_raw.columns[5:22].to_list()\n",
    "df_kier_raw_weather = df_kier_raw[list_col_weather]\n",
    "df_kier_raw_weather.insert(0, 'METER_DATE', df_kier_raw['METER_DATE'])\n",
    "## Usage Data\n",
    "list_kier_h_all = df_kier_raw.columns[22:].to_list()\n",
    "## - 직전 시간 데이터\n",
    "df_kier_raw_prev = df_kier_raw[list_kier_h_all]\n",
    "df_kier_raw_prev.insert(0, 'METER_DATE', df_kier_raw['METER_DATE'])\n",
    "df_kier_raw_prev.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kier_raw_prev['METER_DATE'] = df_kier_raw_prev['METER_DATE'].shift(-1)\n",
    "df_kier_raw_prev.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kier_h_cluster = pd.read_csv(str_dirName_h + str_file_clustering, index_col = 0).rename(columns = {'index' : 'h_index'})[['h_index', 'target_' + str_domain]]\n",
    "list_kier_h_c0 = df_kier_h_cluster[df_kier_h_cluster['target_' + str_domain] == 0]['h_index']\n",
    "print(len(list_kier_h_c0))\n",
    "list_kier_h_c1 = df_kier_h_cluster[df_kier_h_cluster['target_' + str_domain] == 1]['h_index']\n",
    "print(len(list_kier_h_c1))\n",
    "list_kier_h_c2 = df_kier_h_cluster[df_kier_h_cluster['target_' + str_domain] == 2]['h_index']\n",
    "print(len(list_kier_h_c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 전체 사용량 합계\n",
    "df_kier_h_all = df_kier_raw_weather.copy()\n",
    "df_kier_h_tmp = df_kier_raw[list_kier_h_all]\n",
    "df_kier_h_all['ELEC_INST_SUM'] = df_kier_h_tmp.sum(axis = 1)\n",
    "df_kier_h_tmp['METER_DATE'] = df_kier_raw_weather['METER_DATE']\n",
    "df_kier_h_all = pd.merge(df_kier_h_all, df_kier_raw_prev, how = 'left', on = 'METER_DATE').dropna()\n",
    "\n",
    "## Cluster별 사용량 합계\n",
    "## ■ C00\n",
    "df_kier_h_c0 = df_kier_raw_weather.copy()\n",
    "df_kier_h_tmp = df_kier_raw[list_kier_h_c0]\n",
    "df_kier_h_c0['ELEC_INST_SUM_C0'] = df_kier_h_tmp.sum(axis = 1)\n",
    "df_kier_h_tmp['METER_DATE'] = df_kier_raw_weather['METER_DATE']\n",
    "df_kier_h_c0['ELEC_INST_SUM_C0'] = df_kier_h_tmp.sum(axis = 1)\n",
    "df_kier_h_c0 = pd.merge(df_kier_h_c0, df_kier_raw_prev, how = 'left', on = 'METER_DATE').dropna()\n",
    "\n",
    "# ## ■ C01\n",
    "df_kier_h_c1 = df_kier_raw_weather.copy()\n",
    "df_kier_h_tmp = df_kier_raw[list_kier_h_c1]\n",
    "df_kier_h_c1['ELEC_INST_SUM_C1'] = df_kier_h_tmp.sum(axis = 1)\n",
    "df_kier_h_tmp['METER_DATE'] = df_kier_raw_weather['METER_DATE']\n",
    "df_kier_h_c1['ELEC_INST_SUM_C1'] = df_kier_h_tmp.sum(axis = 1)\n",
    "df_kier_h_c1 = pd.merge(df_kier_h_c1, df_kier_raw_prev, how = 'left', on = 'METER_DATE').dropna()\n",
    "\n",
    "# ## ■ C02\n",
    "df_kier_h_c2 = df_kier_raw_weather.copy()\n",
    "df_kier_h_tmp = df_kier_raw[list_kier_h_c2]\n",
    "df_kier_h_c2['ELEC_INST_SUM_C2'] = df_kier_h_tmp.sum(axis = 1)\n",
    "df_kier_h_tmp['METER_DATE'] = df_kier_raw_weather['METER_DATE']\n",
    "df_kier_h_c2['ELEC_INST_SUM_C2'] = df_kier_h_tmp.sum(axis = 1)\n",
    "df_kier_h_c2 = pd.merge(df_kier_h_c2, df_kier_raw_prev, how = 'left', on = 'METER_DATE').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kier_h_c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 전체 사용량 합계\n",
    "# df_kier_h_all = df_kier_raw[list_kier_h_all]\n",
    "# df_kier_h_all['ELEC_INST_SUM'] = df_kier_h_all.sum(axis = 1)\n",
    "# df_kier_h_all.insert(0, 'METER_DATE', df_kier_raw['METER_DATE'])\n",
    "# df_kier_h_all = pd.merge(df_kier_raw_weather, df_kier_h_all\n",
    "#                          , how = 'left', on = ['METER_DATE'])\n",
    "# list_kier_h_all = ['METER_DATE'] + df_kier_raw_weather + ['ELEC_INST_SUM']\n",
    "# df_kier_h_all = df_kier_h_all[list_kier_h_all]\n",
    "\n",
    "# ## Cluster별 사용량 합계\n",
    "# ## ■ C00\n",
    "# df_kier_h_c0 = df_kier_raw[list_kier_h_c0]\n",
    "# df_kier_h_c0['ELEC_INST_SUM_C0'] = df_kier_h_c0.sum(axis = 1)\n",
    "# df_kier_h_c0.insert(0, 'METER_DATE', df_kier_raw['METER_DATE'])\n",
    "# ## 합계행만 남기기 (필요시 세대별 사용량 복원 가능)\n",
    "# df_kier_h_c0 = df_kier_h_c0[['METER_DATE', 'ELEC_INST_SUM_C0']]\n",
    "\n",
    "# ## ■ C01\n",
    "# df_kier_h_c1 = df_kier_raw[list_kier_h_c1]\n",
    "# df_kier_h_c1['ELEC_INST_SUM_C1'] = df_kier_h_c1.sum(axis = 1)\n",
    "# df_kier_h_c1.insert(0, 'METER_DATE', df_kier_raw['METER_DATE'])\n",
    "# ## 합계행만 남기기 (필요시 세대별 사용량 복원 가능)\n",
    "# df_kier_h_c1 = df_kier_h_c1[['METER_DATE', 'ELEC_INST_SUM_C1']]\n",
    "\n",
    "# ## ■ C02\n",
    "# df_kier_h_c2 = df_kier_raw[list_kier_h_c2]\n",
    "# df_kier_h_c2['ELEC_INST_SUM_C2'] = df_kier_h_c2.sum(axis = 1)\n",
    "# df_kier_h_c2.insert(0, 'METER_DATE', df_kier_raw['METER_DATE'])\n",
    "# ## 합계행만 남기기 (필요시 세대별 사용량 복원 가능)\n",
    "# df_kier_h_c2 = df_kier_h_c2[['METER_DATE', 'ELEC_INST_SUM_C2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kier_h_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-03. Data Integeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_file = 'KIER_' + str_domain + '_INST_Weather_ALL_' + str_interval + '.csv'\n",
    "df_kier_h_all.to_csv(str_dirName_h + str_file)\n",
    "print(df_kier_h_all.info())\n",
    "df_kier_h_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_file = 'KIER_' + str_domain + '_INST_Weather_C0_' + str_interval + '.csv'\n",
    "df_kier_h_c0.to_csv(str_dirName_h + str_file)\n",
    "print(df_kier_h_c0.info())\n",
    "df_kier_h_c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_file = 'KIER_' + str_domain + '_INST_Weather_C1_' + str_interval + '.csv'\n",
    "df_kier_h_c1.to_csv(str_dirName_h + str_file)\n",
    "print(df_kier_h_c1.info())\n",
    "df_kier_h_c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_file = 'KIER_' + str_domain + '_INST_Weather_C2_' + str_interval + '.csv'\n",
    "df_kier_h_c2.to_csv(str_dirName_h + str_file)\n",
    "print(df_kier_h_c2.info())\n",
    "df_kier_h_c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
